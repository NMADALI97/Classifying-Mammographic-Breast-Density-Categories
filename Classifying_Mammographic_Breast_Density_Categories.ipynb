{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classifying_Mammographic_Breast_Density_Categories.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HscEHOPV1aJB",
        "colab_type": "code",
        "outputId": "b0ac051a-016c-425d-a6e5-088232317895",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import zipfile, os\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "zip_id = '1upOcakmV4Ym2sv-5K3MY88rA_QNzTXJV'\n",
        "print (\"Downloading zip file\")\n",
        "myzip = drive.CreateFile({'id': zip_id})\n",
        "myzip.GetContentFile('model.zip')\n",
        "print (\"Uncompressing zip file\")\n",
        "zip_ref = zipfile.ZipFile('model.zip', 'r')\n",
        "zip_ref.extractall(\"breast_density_dataset\")\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading zip file\n",
            "Uncompressing zip file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9bDCmLoTOSr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(\"breast_density_dataset/train.csv\")\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "for col in train.columns[2:-1]:\n",
        "  train[col]=le.fit_transform(train[col])\n",
        "train.to_csv(\"breast_density_dataset/train.csv\",index=False)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iELMj1M1dd7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import h5py\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def read_image_and_breast_mask(h5_filename):\n",
        "    # 'r' mode is very important ! \n",
        "    with h5py.File(h5_filename, \"r\") as h5_file:\n",
        "        image = h5_file[\"image\"][:]\n",
        "        breast_mask = h5_file[\"mask\"][:]\n",
        "\n",
        "    return image, breast_mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTpbWFFT2zbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_generator(Train_df,batch_size,steps):\n",
        " idx=1\n",
        " while True: \n",
        "  yield load_data(Train_df,idx-1,batch_size)## Yields data\n",
        "  if idx<steps:\n",
        "    idx+=1\n",
        "  else:\n",
        "    idx=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f6TZR_z2X6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_DIR = \"breast_density_dataset/train/\"\n",
        "TEST_DIR = \"breast_density_dataset/test/\"\n",
        "\n",
        "def load_data(Train_df,idx,batch_size):\n",
        " df = pd.read_csv(\"breast_density_dataset/train.csv\")\n",
        " arr = np.arange(len(df))\n",
        " np.random.shuffle(arr)\n",
        " x = []\n",
        " z = []\n",
        " y = [] \n",
        " for  row  in df.values[arr[0:batch_size],:]:\n",
        "  image_uid=row[0]\n",
        "  image_file = os.path.join(TRAIN_DIR, image_uid + \".h5\")\n",
        "  X, breast_mask = read_image_and_breast_mask(image_file)\n",
        "\n",
        "  image = (X - X.min()) / (X.max() - X.min())\n",
        "  #image =(image*255.).astype('uint8')\n",
        "  \n",
        " # tmp=np.zeros(2)\n",
        " # tmp[row[-2]-1]=1\n",
        "  #latent=np.array(functors([image.reshape(1,288, 208, 1), 1.])).reshape(36, 26, 128)\n",
        "  #z.append(row[2:-1])\n",
        "  x.append(image) \n",
        "  y.append(row[2:] )\n",
        "\n",
        " return (np.array(x).reshape(-1,288,208,1), np.array(y).reshape(-1,5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujU7_58f2iLG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "batch_size=32\n",
        "steps_per_epoch=np.ceil(7960/batch_size)\n",
        "validation_steps=np.ceil(2000/batch_size)\n",
        "\n",
        "my_training_batch_generator = batch_generator('train.csv', 32,steps_per_epoch)\n",
        "my_validation_batch_generator = batch_generator('valid.csv', 32,validation_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "is3ewllkS0dT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x,y=next(my_training_batch_generator) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JF4PM2Up2kH6",
        "colab_type": "code",
        "outputId": "1c9af124-365b-40eb-9bbd-069494309c72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D,Flatten,Reshape,Convolution2D,Cropping2D,Dropout\n",
        "from keras.models import Model\n",
        "from skimage.transform import resize\n",
        "from keras import backend as K\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "\n",
        "\n",
        "input_img = Input(shape=(288,208,1))  # adapt this if using `channels_first` image data format\n",
        "\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(input_img)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
        "x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
        "\n",
        "    # Block 2\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
        "x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
        "\n",
        "    # Block 3\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
        "x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
        "\n",
        "    # Block 4\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
        "x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
        "\n",
        "    # Block 5\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "\n",
        "\n",
        "x=Flatten()(x)\n",
        "x = Dense(1024)(x)\n",
        "\n",
        "x=Dropout(rate=0.4)(x)\n",
        "\n",
        "x = Dense(512)(x)\n",
        "\n",
        "x=Dropout(rate=0.4)(x)\n",
        "\n",
        "x = Dense(256)(x)\n",
        "\n",
        "x=Dropout(rate=0.4)(x)\n",
        "\n",
        "output = Dense(5,activation='relu')(x)\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "model = Model(input_img, [output])\n",
        "model.compile(optimizer='adam', loss=['mse'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         (None, 288, 208, 1)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 288, 208, 64)      640       \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 288, 208, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 144, 104, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 144, 104, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 144, 104, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 72, 52, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 72, 52, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 72, 52, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 72, 52, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 36, 26, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 36, 26, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 36, 26, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 36, 26, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 18, 13, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 18, 13, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 18, 13, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 18, 13, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 9, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 32256)             0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 1024)              33031168  \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 5)                 1285      \n",
            "=================================================================\n",
            "Total params: 48,402,117\n",
            "Trainable params: 48,402,117\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx9eJzq12luU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks = [\n",
        "    EarlyStopping(patience=10, verbose=1),\n",
        "    ReduceLROnPlateau(factor=0.1, patience=3, min_lr=0.00001, verbose=1),\n",
        "    ModelCheckpoint('model-s.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JR1BAHbP2nWX",
        "colab_type": "code",
        "outputId": "8e5d880e-049d-4629-e399-1a78d8005f90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "results = model.fit_generator(my_training_batch_generator,epochs=30,steps_per_epoch=steps_per_epoch,verbose=1, validation_data=my_validation_batch_generator,validation_steps=validation_steps, callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "249/249 [==============================] - 75s 302ms/step - loss: 0.0742 - val_loss: 0.0443\n",
            "\n",
            "Epoch 00001: val_loss improved from 0.04497 to 0.04426, saving model to model-s.h5\n",
            "Epoch 2/30\n",
            "249/249 [==============================] - 75s 302ms/step - loss: 0.0724 - val_loss: 0.0411\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.04426 to 0.04106, saving model to model-s.h5\n",
            "Epoch 3/30\n",
            "249/249 [==============================] - 75s 301ms/step - loss: 0.0694 - val_loss: 0.0394\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.04106 to 0.03943, saving model to model-s.h5\n",
            "Epoch 4/30\n",
            "249/249 [==============================] - 75s 301ms/step - loss: 0.0694 - val_loss: 0.0408\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.03943\n",
            "Epoch 5/30\n",
            "249/249 [==============================] - 75s 301ms/step - loss: 0.0645 - val_loss: 0.0362\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.03943 to 0.03619, saving model to model-s.h5\n",
            "Epoch 6/30\n",
            "249/249 [==============================] - 75s 301ms/step - loss: 0.0643 - val_loss: 0.0343\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.03619 to 0.03430, saving model to model-s.h5\n",
            "Epoch 7/30\n",
            "249/249 [==============================] - 75s 300ms/step - loss: 0.0631 - val_loss: 0.0352\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.03430\n",
            "Epoch 8/30\n",
            "249/249 [==============================] - 75s 300ms/step - loss: 0.0612 - val_loss: 0.0324\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.03430 to 0.03238, saving model to model-s.h5\n",
            "Epoch 9/30\n",
            "249/249 [==============================] - 75s 301ms/step - loss: 0.0592 - val_loss: 0.0322\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.03238 to 0.03216, saving model to model-s.h5\n",
            "Epoch 10/30\n",
            "249/249 [==============================] - 75s 301ms/step - loss: 0.0583 - val_loss: 0.0323\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.03216\n",
            "Epoch 11/30\n",
            "249/249 [==============================] - 75s 300ms/step - loss: 0.0561 - val_loss: 0.0294\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.03216 to 0.02944, saving model to model-s.h5\n",
            "Epoch 12/30\n",
            "249/249 [==============================] - 75s 300ms/step - loss: 0.0550 - val_loss: 0.0284\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.02944 to 0.02845, saving model to model-s.h5\n",
            "Epoch 13/30\n",
            "249/249 [==============================] - 75s 300ms/step - loss: 0.0527 - val_loss: 0.0254\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.02845 to 0.02544, saving model to model-s.h5\n",
            "Epoch 14/30\n",
            "249/249 [==============================] - 75s 301ms/step - loss: 0.0511 - val_loss: 0.0252\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.02544 to 0.02521, saving model to model-s.h5\n",
            "Epoch 15/30\n",
            "249/249 [==============================] - 75s 300ms/step - loss: 0.0505 - val_loss: 0.0261\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.02521\n",
            "Epoch 16/30\n",
            "249/249 [==============================] - 75s 300ms/step - loss: 0.0489 - val_loss: 0.0241\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.02521 to 0.02412, saving model to model-s.h5\n",
            "Epoch 17/30\n",
            "249/249 [==============================] - 75s 300ms/step - loss: 0.0470 - val_loss: 0.0229\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.02412 to 0.02292, saving model to model-s.h5\n",
            "Epoch 18/30\n",
            "249/249 [==============================] - 75s 300ms/step - loss: 0.0460 - val_loss: 0.0238\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.02292\n",
            "Epoch 19/30\n",
            "249/249 [==============================] - 75s 300ms/step - loss: 0.0450 - val_loss: 0.0204\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.02292 to 0.02037, saving model to model-s.h5\n",
            "Epoch 20/30\n",
            "249/249 [==============================] - 75s 300ms/step - loss: 0.0436 - val_loss: 0.0188\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.02037 to 0.01883, saving model to model-s.h5\n",
            "Epoch 21/30\n",
            "249/249 [==============================] - 75s 300ms/step - loss: 0.0430 - val_loss: 0.0190\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.01883\n",
            "Epoch 22/30\n",
            "249/249 [==============================] - 75s 301ms/step - loss: 0.0421 - val_loss: 0.0172\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.01883 to 0.01723, saving model to model-s.h5\n",
            "Epoch 23/30\n",
            "249/249 [==============================] - 75s 300ms/step - loss: 0.0400 - val_loss: 0.0169\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.01723 to 0.01688, saving model to model-s.h5\n",
            "Epoch 24/30\n",
            "249/249 [==============================] - 75s 301ms/step - loss: 0.0392 - val_loss: 0.0150\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.01688 to 0.01502, saving model to model-s.h5\n",
            "Epoch 25/30\n",
            "249/249 [==============================] - 75s 301ms/step - loss: 0.0382 - val_loss: 0.0154\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.01502\n",
            "Epoch 26/30\n",
            "249/249 [==============================] - 75s 301ms/step - loss: 0.0377 - val_loss: 0.0145\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.01502 to 0.01447, saving model to model-s.h5\n",
            "Epoch 27/30\n",
            "249/249 [==============================] - 75s 301ms/step - loss: 0.0358 - val_loss: 0.0141\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.01447 to 0.01413, saving model to model-s.h5\n",
            "Epoch 28/30\n",
            "249/249 [==============================] - 75s 301ms/step - loss: 0.0354 - val_loss: 0.0122\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.01413 to 0.01215, saving model to model-s.h5\n",
            "Epoch 29/30\n",
            "249/249 [==============================] - 75s 300ms/step - loss: 0.0345 - val_loss: 0.0140\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.01215\n",
            "Epoch 30/30\n",
            "249/249 [==============================] - 75s 300ms/step - loss: 0.0342 - val_loss: 0.0138\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.01215\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vU6I_Iy-XyWb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights('model-s.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPuHtC68X78O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"breast_density_dataset/train.csv\")\n",
        "s=0\n",
        "for  row  in df.values:\n",
        "  image_uid=row[0]\n",
        "  image_file = os.path.join(TRAIN_DIR, image_uid + \".h5\")\n",
        "  X, breast_mask = read_image_and_breast_mask(image_file)\n",
        "  image = (X - X.min()) / (X.max() - X.min())\n",
        "  tmp=model.predict(image.reshape(1,288, 208, 1))\n",
        "  p=np.abs(np.round(tmp.reshape(-1)))\n",
        "  if p[-1]==row[-1]:\n",
        "    s+=1\n",
        "print(\"precision :\"+str(s/len(df)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5M9Tlu71YlpR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = pd.read_csv(\"breast_density_dataset/test.csv\")\n",
        "TRAIN_DIR=\"breast_density_dataset/test\"\n",
        "y_pred=[]\n",
        "for  row  in test.values:\n",
        "  image_uid=row[0]\n",
        "  image_file = os.path.join(TEST_DIR, image_uid + \".h5\")\n",
        "  X, breast_mask = read_image_and_breast_mask(image_file)\n",
        "  image = (X - X.min()) / (X.max() - X.min())\n",
        "  tmp=model.predict(image.reshape(1,288, 208, 1))\n",
        "  p=np.abs(np.round(tmp.reshape(-1)))\n",
        "  y_pred.append(int(p[-1]))\n",
        "\n",
        "test[\"breast_density_score\"]=y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMBbsw7KZOED",
        "colab_type": "code",
        "outputId": "e192ce0b-ff67-40ba-f677-00f69d907691",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_uid</th>\n",
              "      <th>study_uid</th>\n",
              "      <th>source</th>\n",
              "      <th>manufacturer</th>\n",
              "      <th>view</th>\n",
              "      <th>laterality</th>\n",
              "      <th>breast_density_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bKoUoJrTDD</td>\n",
              "      <td>rvVNQjBYXRDgWGZabWmB</td>\n",
              "      <td>ANI</td>\n",
              "      <td>C</td>\n",
              "      <td>CC</td>\n",
              "      <td>L</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>jIvyWDKyKo</td>\n",
              "      <td>rvVNQjBYXRDgWGZabWmB</td>\n",
              "      <td>ANI</td>\n",
              "      <td>C</td>\n",
              "      <td>MLO</td>\n",
              "      <td>L</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>YLYzzzqCws</td>\n",
              "      <td>rvVNQjBYXRDgWGZabWmB</td>\n",
              "      <td>ANI</td>\n",
              "      <td>C</td>\n",
              "      <td>CC</td>\n",
              "      <td>R</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>kxORhMlINs</td>\n",
              "      <td>rvVNQjBYXRDgWGZabWmB</td>\n",
              "      <td>ANI</td>\n",
              "      <td>C</td>\n",
              "      <td>MLO</td>\n",
              "      <td>R</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tesbnsFvoZ</td>\n",
              "      <td>xXGLZUFkRfyaIdjDlUkN</td>\n",
              "      <td>ANI</td>\n",
              "      <td>B</td>\n",
              "      <td>CC</td>\n",
              "      <td>L</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    image_uid             study_uid  ... laterality breast_density_score\n",
              "0  bKoUoJrTDD  rvVNQjBYXRDgWGZabWmB  ...          L                    1\n",
              "1  jIvyWDKyKo  rvVNQjBYXRDgWGZabWmB  ...          L                    1\n",
              "2  YLYzzzqCws  rvVNQjBYXRDgWGZabWmB  ...          R                    2\n",
              "3  kxORhMlINs  rvVNQjBYXRDgWGZabWmB  ...          R                    2\n",
              "4  tesbnsFvoZ  xXGLZUFkRfyaIdjDlUkN  ...          L                    3\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn82DzVgZ9ck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.to_csv(\"submissions.csv\",index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}